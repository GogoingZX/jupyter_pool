{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "toc": true
   },
   "source": [
    "<h1>Table of Contents<span class=\"tocSkip\"></span></h1>\n",
    "<div class=\"toc\"><ul class=\"toc-item\"><li><span><a href=\"#Settings\" data-toc-modified-id=\"Settings-1\"><span class=\"toc-item-num\">1&nbsp;&nbsp;</span>Settings</a></span></li><li><span><a href=\"#Build-Decision-Tree-(ID3)\" data-toc-modified-id=\"Build-Decision-Tree-(ID3)-2\"><span class=\"toc-item-num\">2&nbsp;&nbsp;</span>Build Decision Tree (ID3)</a></span><ul class=\"toc-item\"><li><span><a href=\"#Calculate-Shannon-Entropy\" data-toc-modified-id=\"Calculate-Shannon-Entropy-2.1\"><span class=\"toc-item-num\">2.1&nbsp;&nbsp;</span>Calculate Shannon Entropy</a></span></li><li><span><a href=\"#Split-Dataset-Based-on-Information-Gain\" data-toc-modified-id=\"Split-Dataset-Based-on-Information-Gain-2.2\"><span class=\"toc-item-num\">2.2&nbsp;&nbsp;</span>Split Dataset Based on Information Gain</a></span></li><li><span><a href=\"#Create-Tree\" data-toc-modified-id=\"Create-Tree-2.3\"><span class=\"toc-item-num\">2.3&nbsp;&nbsp;</span>Create Tree</a></span></li><li><span><a href=\"#Check-Tree-Info\" data-toc-modified-id=\"Check-Tree-Info-2.4\"><span class=\"toc-item-num\">2.4&nbsp;&nbsp;</span>Check Tree Info</a></span></li><li><span><a href=\"#Save-&amp;-Load-Model\" data-toc-modified-id=\"Save-&amp;-Load-Model-2.5\"><span class=\"toc-item-num\">2.5&nbsp;&nbsp;</span>Save &amp; Load Model</a></span></li></ul></li><li><span><a href=\"#Practice\" data-toc-modified-id=\"Practice-3\"><span class=\"toc-item-num\">3&nbsp;&nbsp;</span>Practice</a></span></li></ul></div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-11-23T17:48:08.301490Z",
     "start_time": "2021-11-23T17:48:07.439640Z"
    }
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "import time\n",
    "import datetime\n",
    "import pickle\n",
    "import json\n",
    "import re\n",
    "import operator\n",
    "\n",
    "from math import log\n",
    "from collections import defaultdict\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "from IPython.core.interactiveshell import InteractiveShell\n",
    "InteractiveShell.ast_node_interactivity = \"all\"\n",
    "\n",
    "\n",
    "sys.path.append(\"/Users/xuzhu/Desktop/code/assistants\") # my package\n",
    "from toolbox.os_assistant import scan_folder"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-11-24T13:43:44.989949Z",
     "start_time": "2021-11-24T13:43:44.982774Z"
    }
   },
   "outputs": [],
   "source": [
    "DATA_FOLDER = \"/Users/xuzhu/Desktop/data/open_dataset\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Given a discrete random variable $X$, with possible outcomes $x_{1},..., x_{n}$, which occur with probability $P(x_{n}),..., P(x_{n})$, the **<font color=red>entropy</font>** of $X$ is formally defined as:<br>\n",
    "$$H = - \\sum^{n}_{i=1} p(x_{i}) log_{2} p(x_{i})$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-11-24T13:59:42.358096Z",
     "start_time": "2021-11-24T13:59:42.341441Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>is_big</th>\n",
       "      <th>is_white</th>\n",
       "      <th>good</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Y</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>N</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Y</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>N</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>N</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   is_big  is_white good\n",
       "0       1         1    Y\n",
       "1       1         0    N\n",
       "2       1         1    Y\n",
       "3       0         1    N\n",
       "4       0         1    N"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "raw_data = [\n",
    "    [1, 1, \"Y\"],\n",
    "    [1, 0, \"N\"],\n",
    "    [1, 1, \"Y\"],\n",
    "    [0, 1, \"N\"],\n",
    "    [0, 1, \"N\"]\n",
    "]\n",
    "\n",
    "raw_df = pd.DataFrame(\n",
    "    data=raw_data,\n",
    "    columns=[\"is_big\", \"is_white\", \"good\"]\n",
    ")\n",
    "\n",
    "raw_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build Decision Tree (ID3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Calculate Shannon Entropy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-11-24T14:16:19.742354Z",
     "start_time": "2021-11-24T14:16:19.732529Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9709505944546686"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def calculate_shannon_entropy(df):\n",
    "    \"\"\"\n",
    "    Calculate Shannon entropy of the dataset\n",
    "    \"\"\"\n",
    "    entity_qty = df.shape[0]\n",
    "    class_stats = defaultdict(int)\n",
    "    for index, row in df.iterrows():\n",
    "        current_class = row[-1]\n",
    "        class_stats[current_class] += 1\n",
    "    \n",
    "    shannon_entropy = 0\n",
    "    for key in class_stats.keys():\n",
    "        class_prob = class_stats[key] / entity_qty\n",
    "        shannon_entropy = shannon_entropy - class_prob * log(class_prob, 2)\n",
    "    \n",
    "    return shannon_entropy\n",
    "        \n",
    "calculate_shannon_entropy(raw_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Split Dataset Based on Information Gain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-11-24T16:38:03.514230Z",
     "start_time": "2021-11-24T16:38:03.495035Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>is_white</th>\n",
       "      <th>good</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>N</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>N</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  is_white good\n",
       "0        1    N\n",
       "1        1    N"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def split_dataset(\n",
    "    df,\n",
    "    feature_name,\n",
    "    feature_value\n",
    "):\n",
    "    \"\"\"\n",
    "    Split dataset based on Shannon entropy\n",
    "    \n",
    "    If the entity's feature value = specific feature value\n",
    "    ==> matched, grab this entity and delete this used feature to build a new dataset\n",
    "    ==> all features only use once in this algorithm !!!\n",
    "    \"\"\"\n",
    "    \n",
    "    col_list = df.columns.to_list()\n",
    "    col_list.remove(feature_name)\n",
    "    new_df = pd.DataFrame(columns=col_list) # make sure the column position unchanged\n",
    "    \n",
    "    for index, row in df.iterrows(): # scan all rows\n",
    "        if row[feature_name] == feature_value: \n",
    "            new_row = row.drop(feature_name)\n",
    "            new_df = new_df.append(new_row, ignore_index=True) # Q: why does the col index change randomly?\n",
    "        else: # not matched\n",
    "            pass\n",
    "    \n",
    "    return new_df\n",
    "            \n",
    "split_dataset(\n",
    "    df=raw_df,\n",
    "    feature_name=\"is_big\",\n",
    "    feature_value=0\n",
    ")     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-11-24T16:38:18.193333Z",
     "start_time": "2021-11-24T16:38:18.121377Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'is_big'"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def choose_best_feature_to_split(df):\n",
    "    \"\"\"\n",
    "    Compare different features and choose the best one to split the dataset\n",
    "    \n",
    "    信息增益代表了在一个条件下, 信息复杂度(不确定性)减少的程度\n",
    "    如果选择一个特征, 信息增益最大(信息不确定性减少的程度最大), 那么我们就选取这个特征\n",
    "    信息增益 = 信息熵 - 条件熵\n",
    "    ==> https://zhuanlan.zhihu.com/p/26596036\n",
    "    \"\"\"\n",
    "    entropy__base = calculate_shannon_entropy(df)\n",
    "    info_gain__max = 0\n",
    "    \n",
    "    # feature_qty = len(df.columns) - 1 # assume the last one column is the label\n",
    "    feature_name_list = df.columns.to_list()[:-1] # exclude the label\n",
    "    feature_qty = len(feature_name_list)\n",
    "    best_feature_name = feature_name_list[-1]\n",
    "    \n",
    "    for feature_name in feature_name_list: # scan all feature columns\n",
    "        # split dataset by using this feature, calculate the information gain\n",
    "        current_feature_value_list = [row[feature_name] for index, row in df.iterrows()]\n",
    "        uniq_feature_value_set = set(current_feature_value_list) # uniq value (or we can say 'class')\n",
    "        \n",
    "        entropy__condition = 0\n",
    "        for feature_value in uniq_feature_value_set: # calculate the conditional entropy\n",
    "            df__new = split_dataset(\n",
    "                df=df,\n",
    "                feature_name=feature_name,\n",
    "                feature_value=feature_value\n",
    "            )\n",
    "            prob = df__new.shape[0] / df.shape[0] # calculate the probability of the subclass\n",
    "            entropy__condition = entropy__condition + prob * calculate_shannon_entropy(df__new)\n",
    "        \n",
    "        info_gain = entropy__base - entropy__condition\n",
    "        if info_gain > info_gain__max:\n",
    "            info_gain__max = info_gain\n",
    "            best_feature_name = feature_name\n",
    "        else:\n",
    "            pass\n",
    "    \n",
    "    return best_feature_name\n",
    "            \n",
    "choose_best_feature_to_split(raw_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-11-24T16:38:20.567938Z",
     "start_time": "2021-11-24T16:38:20.556438Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('k2', 2), ('k1', 1)]"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "'a'"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def majority_vote(class_list):\n",
    "    class_stats = {}\n",
    "    for class_value in class_list:\n",
    "        if class_value not in class_stats.keys():\n",
    "            class_stats[class_value] = 0\n",
    "        else:\n",
    "            class_stats[class_value] += 1\n",
    "        \n",
    "    sorted_class_list = sorted(\n",
    "        class_stats.items(),\n",
    "        key=operator.itemgetter(1),\n",
    "        reverse=True\n",
    "    )\n",
    "    # [(key, value), (key, value),... ]\n",
    "    \n",
    "    majority_class_value = sorted_class_list[0][0] # choose the key (class value) of the first element\n",
    "    return majority_class_value\n",
    "\n",
    "\n",
    "t = {\n",
    "    \"k1\": 1,\n",
    "    \"k2\": 2\n",
    "}\n",
    "sorted(t.items(), key=operator.itemgetter(1), reverse=True)\n",
    "\n",
    "majority_vote([\"a\", \"b\", \"a\", \"c\", \"b\", \"a\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-11-24T16:45:27.301648Z",
     "start_time": "2021-11-24T16:45:27.198678Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'is_big': {0: 'N', 1: {'is_white': {0: 'N', 1: 'Y'}}}}"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def create_decision_tree__id3(df):\n",
    "    \"\"\"\n",
    "    Create a decision tree based on ID3 algorithm\n",
    "    All features will be used once only\n",
    "    \"\"\"\n",
    "    label_list = [row[-1] for index, row in df.iterrows()]\n",
    "    if label_list.count(label_list[0]) == len(label_list): # stop condition 1: only 1 class ==> leaf node\n",
    "        label = label_list[0]\n",
    "        return label\n",
    "    if len(df.iloc[0]) == 1: # stop condition 2: no other features\n",
    "        # used all features but there still be several classes\n",
    "        # need choose the majority class\n",
    "        label = majority_vote(label_list)\n",
    "        return label\n",
    "    \n",
    "    feature_name_list = df.columns.to_list()[:-1] # exclude the label\n",
    "    feature_name = choose_best_feature_to_split(df)\n",
    "    tree = {\n",
    "        feature_name: {}\n",
    "    }\n",
    "    feature_name_list.remove(feature_name)\n",
    "    \n",
    "    feature_value_list = [row[feature_name] for index, row in df.iterrows()]\n",
    "    uniq_feature_value_set = set(feature_value_list)\n",
    "    for feature_value in uniq_feature_value_set:\n",
    "        sub_df = split_dataset(\n",
    "            df=df,\n",
    "            feature_name=feature_name,\n",
    "            feature_value=feature_value\n",
    "        )\n",
    "        \n",
    "        tree[feature_name][feature_value] = create_decision_tree__id3(df=sub_df)\n",
    "        \n",
    "    return tree\n",
    "\n",
    "    \n",
    "raw_tree = create_decision_tree__id3(raw_df)\n",
    "raw_tree"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Check Tree Info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-11-24T16:45:40.533124Z",
     "start_time": "2021-11-24T16:45:40.526111Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def get_leaf_qty(tree_dict):\n",
    "    leaf_qty = 0\n",
    "    first_feature = list(tree_dict.keys())[0]\n",
    "    \n",
    "    sub_tree_dict = tree_dict[first_feature]\n",
    "    for key in sub_tree_dict.keys():\n",
    "        if type(sub_tree_dict[key]).__name__ == \"dict\":\n",
    "            leaf_qty += get_leaf_qty(sub_tree_dict[key])\n",
    "        else:\n",
    "            leaf_qty += 1\n",
    "            \n",
    "    return leaf_qty\n",
    "\n",
    "get_leaf_qty(raw_tree)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-11-24T16:53:54.616901Z",
     "start_time": "2021-11-24T16:53:54.610053Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def get_tree_depth(tree_dict):\n",
    "    depth__max = 0\n",
    "    first_feature = list(tree_dict.keys())[0]\n",
    "    \n",
    "    sub_tree_dict = tree_dict[first_feature]\n",
    "    for key in sub_tree_dict.keys():\n",
    "        if type(sub_tree_dict[key]) is dict:\n",
    "            depth__current = 1 + get_tree_depth(sub_tree_dict[key])\n",
    "        else:\n",
    "            depth__current = 1\n",
    "        \n",
    "        if depth__current > depth__max:\n",
    "            depth__max = depth__current\n",
    "    \n",
    "    return depth__max\n",
    "\n",
    "get_tree_depth(raw_tree)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save & Load Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-11-24T17:03:04.883704Z",
     "start_time": "2021-11-24T17:03:04.877628Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'20211125'"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output_folder = os.path.join(DATA_FOLDER, \"test__decision_tree\")\n",
    "\n",
    "today_str = datetime.datetime.today().strftime(\"%Y%m%d\") # yyyymmdd\n",
    "today_str\n",
    "\n",
    "output_filepath = os.path.join(output_folder, \"decision_tree__id3__v{0}.txt\".format(today_str))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-11-24T17:04:05.656741Z",
     "start_time": "2021-11-24T17:04:05.650362Z"
    }
   },
   "outputs": [],
   "source": [
    "def save_tree(\n",
    "    input_tree,\n",
    "    filepath\n",
    "):\n",
    "    with open(filepath, \"wb\") as f_write:\n",
    "        pickle.dump(input_tree, f_write)\n",
    "\n",
    "save_tree(\n",
    "    input_tree=raw_tree,\n",
    "    filepath=output_filepath\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-11-24T17:05:41.775542Z",
     "start_time": "2021-11-24T17:05:41.767772Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'is_big': {0: 'N', 1: {'is_white': {0: 'N', 1: 'Y'}}}}"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def load_tree(filepath):\n",
    "    with open(filepath, \"rb\") as f_read:\n",
    "        tree = pickle.load(f_read)\n",
    "    \n",
    "    return tree\n",
    "\n",
    "loaded_tree = load_tree(output_filepath)\n",
    "loaded_tree"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Practice"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": true,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": true,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "184px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
